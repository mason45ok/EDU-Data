{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20dtxMl7TbDa"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffheaton/present/blob/master/youtube/video/fft-frequency.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "Copyright 2022 by [Jeff Heaton](https://www.heatonresearch.com/), released under [LGPLv3](https://www.gnu.org/licenses/lgpl-3.0.en.html)\n",
        "\n",
        "[YouTube video about this code](https://www.youtube.com/watch?v=rj9NOiFLxWA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQI4U7A1h34o",
        "outputId": "c1c0805f-3d85-4822-9d48-0a1b568a137c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: not using Google CoLab\n",
            "Requirement already satisfied: kaleido in c:\\users\\mason\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.2.1)\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False\n",
        "\n",
        "PATH = \"C:/Users/mason/Desktop/作業/科技系/教育大數據專題製作/EDU-Data/output/audio.wav\"\n",
        "\n",
        "! pip install -U kaleido\n",
        "\n",
        "# 配置\n",
        "FPS = 30\n",
        "FFT_WINDOW_SECONDS = 0.25 # 音頻中每個 FFT 窗口的秒數\n",
        "\n",
        "# 顯示的音符範圍\n",
        "FREQ_MIN = 10\n",
        "FREQ_MAX = 1000\n",
        "\n",
        "# 要顯示的音符數量\n",
        "TOP_NOTES = 3\n",
        "\n",
        "# 音符的名稱\n",
        "NOTE_NAMES = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"]\n",
        "\n",
        "# 輸出的尺寸。通常使用 SCALE 以獲得更高的分辨率，除非你需要非標準的長寬比。\n",
        "RESOLUTION = (1920, 1080)\n",
        "SCALE = 2 # 0.5=QHD(960x540), 1=HD(1920x1080), 2=4K(3840x2160)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9eOd8Tm-jIW5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16000\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "object of type 'numpy.int16' has no len()",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[5], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m FRAME_STEP \u001b[38;5;241m=\u001b[39m (fs \u001b[38;5;241m/\u001b[39m FPS) \u001b[38;5;66;03m# audio samples per video frame\u001b[39;00m\n\u001b[0;32m     17\u001b[0m FFT_WINDOW_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(fs \u001b[38;5;241m*\u001b[39m FFT_WINDOW_SECONDS)\n\u001b[1;32m---> 18\u001b[0m AUDIO_LENGTH \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m/\u001b[39mfs\n",
            "\u001b[1;31mTypeError\u001b[0m: object of type 'numpy.int16' has no len()"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy.fftpack import fft\n",
        "from scipy.io import wavfile # get the api\n",
        "import os\n",
        "#!pip install -U kaleido\n",
        "# Get a WAV file from GDrive, such as:\n",
        "# AUDIO_FILE = os.path.join(PATH,'short_popcorn.wav')\n",
        "\n",
        "# Or download my sample audio\n",
        "#!wget https://github.com/jeffheaton/present/raw/master/youtube/video/sample_audio/piano_c_major_scale.wav\n",
        "AUDIO_FILE = PATH\n",
        "\n",
        "fs, data = wavfile.read(os.path.join(PATH,AUDIO_FILE)) # load the data\n",
        "print(fs)\n",
        "audio = data.T[0] # this is a two channel soundtrack, get the first track\n",
        "FRAME_STEP = (fs / FPS) # audio samples per video frame\n",
        "FFT_WINDOW_SIZE = int(fs * FFT_WINDOW_SECONDS)\n",
        "AUDIO_LENGTH = len(audio)/fs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqxOflIuM_eT"
      },
      "source": [
        "Several utility functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yg2kx9olG3ib"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "def plot_fft(p, xf, fs, notes, dimensions=(960,540)):\n",
        "  \n",
        "\n",
        "  \"\"\"\n",
        "  繪製FFT（快速傅立葉變換）頻譜圖，並在圖上標註頂部音符。\n",
        "\n",
        "  參數:\n",
        "  p (numpy.ndarray): 幅值頻譜。\n",
        "  xf (numpy.ndarray): 頻率值。\n",
        "  fs (float): 取樣頻率。\n",
        "  notes (list): 要在圖上標註的頂部音符列表。\n",
        "  dimensions (tuple): 圖的尺寸（寬度，高度）。\n",
        "\n",
        "  返回:\n",
        "  go.Figure: Plotly 圖形對象。\n",
        "  \"\"\"\n",
        "\n",
        "  layout = go.Layout(       # 圖形參數\n",
        "    title=\"frequency spectrum\",\n",
        "    autosize=False,\n",
        "    width=dimensions[0],\n",
        "    height=dimensions[1],\n",
        "    xaxis_title=\"Frequency (note)\",\n",
        "    yaxis_title=\"Magnitude\",\n",
        "    font={'size' : 24}\n",
        "  )\n",
        "\n",
        "  fig = go.Figure(layout=layout,          # go.Figure圖形形狀創建  layout設置圖形的布局參數\n",
        "                  layout_xaxis_range=[FREQ_MIN,FREQ_MAX], #設圖形中xy軸範圍\n",
        "                  layout_yaxis_range=[0,1]\n",
        "                  )\n",
        "  \n",
        "  fig.add_trace(go.Scatter(     #這條折線圖代表了 FFT 後得到的頻譜數據  fig.add_trace加入圖形，go.Scatter繪製折線圖\n",
        "    x = xf,\n",
        "    y = p))\n",
        "    #這行程式碼將一條折線圖添加到 Plotly 圖形中。x 軸的數據是 xf，即頻率值；y 軸的數據是 p，即幅值頻譜。\n",
        "\n",
        "  \n",
        "  for note in notes:        #在 Plotly 圖形中標註頂部音符的位置和內容\n",
        "    fig.add_annotation(x=note[0]+10, y=note[2], #fig.add_annotation註釋添加到圖形中\n",
        "            text=note[1],\n",
        "            font = {'size' : 48},\n",
        "            showarrow=False)\n",
        "  return fig\n",
        "\n",
        "def extract_sample(audio, frame_number):\n",
        "\n",
        "  \"\"\"\n",
        "  提取給定幀數的音頻樣本。\n",
        "\n",
        "  參數:\n",
        "  audio (numpy.ndarray): 音頻數據。\n",
        "  frame_number (int): 幀數。\n",
        "\n",
        "  返回:\n",
        "  numpy.ndarray: 提取的音頻樣本。\n",
        "  \"\"\"\n",
        "  end = frame_number * FRAME_OFFSET   #開始位置\n",
        "  begin = int(end - FFT_WINDOW_SIZE)  #結束位置\n",
        "\n",
        "  if end == 0:\n",
        "        # 沒有音頻數據，返回全零（開始）\n",
        "    return np.zeros((np.abs(begin)),dtype=float)    \n",
        "  elif begin<0:\n",
        "        # 有一些音頻數據，填充零\n",
        "    return np.concatenate([np.zeros((np.abs(begin)),dtype=float),audio[0:end]]) \n",
        "  else:\n",
        "        # 通常情況，返回下一個樣本\n",
        "    return audio[begin:end]    \n",
        "  #這段程式碼確保了從音訊數據中提取的時間片段具有一定的長度並且在邊界條件下有所處理，從而確保了後續處理的準確性和穩定性。  \n",
        "    \n",
        "\n",
        "def freq_to_number(freq):\n",
        "    \"\"\"\n",
        "    将频率转换为音符数字。\n",
        "    \n",
        "    参数:\n",
        "    freq (float): 频率。\n",
        "    \n",
        "    返回:\n",
        "    float: 音符数字。\n",
        "    \"\"\"\n",
        "    if freq == 0:\n",
        "        return float('-inf')  # 返回负无穷大，避免溢出错误\n",
        "    if np.max(fft.real) < 0.001:  # 如果 FFT 頻譜中的最大實部值小於 0.001，則返回空列表 (音樂太短或音頻太高或低)\n",
        "        return []  # 如果大於 0.001，則按照 fft.real 實部值排列大到小\n",
        "\n",
        "    lst = [(x, y) for x, y in enumerate(fft.real)]  # 將排好的序列轉換為一個列表 (編號,實數值)\n",
        "    # lst = [ (0,fft.real[0]), (1,fft.real[1]), .....]\n",
        "    lst = sorted(lst, key=lambda x: x[1], reverse=True)  # 用 sorted 將 lst[] 按照指定的鍵 key，按照每個元素的第二個值(實部值)為依據進行排列，分析音樂信號中的頻率成分\n",
        "    # lst[ (fft.real[0]), (fft.real[1]) ,....]\n",
        "    idx = 0\n",
        "    found = []  # 創建空列表[]\n",
        "    found_note = set()  # 創建空集合{}   儲存已經找到的音符\n",
        "    while idx < len(lst) and len(found) < num:  # 重複直到找到全部音符或全部跑完lst len<0 or idx>len\n",
        "        f = lst[idx][0]  # f 頻率\n",
        "        y = lst[idx][1]  # FFT 頻譜中對應的幅值\n",
        "        n = freq_to_number(f)  # 計算頻率對應的音符數字\n",
        "        n0 = int(round(n))  # round 四捨五入\n",
        "        name = note_name(n0)  # 將數字轉為音符名稱\n",
        "\n",
        "        if name not in found_note:  # 加入音符到集合\n",
        "            found_note.add(name)\n",
        "            s = [f, name, y]\n",
        "            found.append(s)\n",
        "        idx += 1\n",
        "\n",
        "    return found  # 返回全部音符的種類數量"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t98k4AMRHy-o"
      },
      "source": [
        "Run the FFT on individual samples of the audio and generate video frames of the frequency chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFyeZ44Cr5TI",
        "outputId": "73fd185b-c7b1-42cd-c62e-c3b64f617308"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'AUDIO_LENGTH' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 30\u001b[0m\n\u001b[0;32m     26\u001b[0m xf \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfft\u001b[38;5;241m.\u001b[39mrfftfreq(FFT_WINDOW_SIZE, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mfs) \u001b[38;5;66;03m#(實數值 生成動畫)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m\"\"\"這行程式碼是用來產生傅立葉變換後的頻率軸\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03m傅立葉變換通常返回實部和虛部，因此對於實數信號，通常只需考慮其中一半的頻譜，即正頻譜。\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m FRAME_COUNT \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[43mAUDIO_LENGTH\u001b[49m\u001b[38;5;241m*\u001b[39mFPS)\n\u001b[0;32m     31\u001b[0m FRAME_OFFSET \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(audio)\u001b[38;5;241m/\u001b[39mFRAME_COUNT)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m#(漢寧窗就像是給聲音穿上了一個保護罩，讓我們更清楚地聽到聲音的細節，減少其他聲音的干擾。)\u001b[39;00m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'AUDIO_LENGTH' is not defined"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tqdm\n",
        "#plot_fft動畫圖形，find_top_notes找音符，found頂部音符，extract_sample確保不發生錯誤\n",
        "\n",
        "# 清理以 .png 結尾的文件\n",
        "#!rm /content/*.png\n",
        "#!pip install -U kaleido\n",
        "#$pip install -U kaleido\n",
        "\n",
        "# 轉換頻率到音符數字\n",
        "def freq_to_number(f): \n",
        "  if f <= 0:\n",
        "    return -1  # 或者返回其他特定值来表示无效的频率\n",
        "  return 69 + 12*np.log2(f/440.0)\n",
        "\n",
        "# 轉換音符數字到頻率\n",
        "def number_to_freq(n): return 440 * 2.0**((n-69)/12.0)\n",
        "\n",
        "# 獲取音符名稱\n",
        "def note_name(n): return NOTE_NAMES[n % 12] + str(int(n/12 - 1))\n",
        "\n",
        "# 漢寧窗口函數\n",
        "window = 0.5 * (1 - np.cos(np.linspace(0, 2*np.pi, FFT_WINDOW_SIZE, False)))\n",
        "\n",
        "# 計算 FFT 的頻率\n",
        "xf = np.fft.rfftfreq(FFT_WINDOW_SIZE, 1/fs) #(實數值 生成動畫)\n",
        "\"\"\"這行程式碼是用來產生傅立葉變換後的頻率軸\n",
        "傅立葉變換通常返回實部和虛部，因此對於實數信號，通常只需考慮其中一半的頻譜，即正頻譜。\n",
        "\"\"\"\n",
        "FRAME_COUNT = int(AUDIO_LENGTH*FPS)\n",
        "FRAME_OFFSET = int(len(audio)/FRAME_COUNT)\n",
        "\n",
        "#(漢寧窗就像是給聲音穿上了一個保護罩，讓我們更清楚地聽到聲音的細節，減少其他聲音的干擾。)\n",
        "\n",
        "def frequency_to_freq_domain_signal(top_notes_list, fs, N): #將頻率信息轉換為對應的頻域信號\n",
        "    freq_domain_signal = np.zeros(N)  # 創建長度為 N 的頻域信號\n",
        "    \n",
        "    # 對於每個主要音符，設置頻域信號的相應位置為振幅或能量值\n",
        "    for note in top_notes_list:\n",
        "        frequency = note[0]  # 音符的頻率\n",
        "        amplitude = note[2]  # 音符的振幅或能量值\n",
        "        index = int(frequency * N / fs)  # 計算頻率對應的索引\n",
        "        freq_domain_signal[index] = amplitude  # 將振幅或能量值設置到頻域信號中的相應位置\n",
        "    \n",
        "    return freq_domain_signal\n",
        "\n",
        "\n",
        "\n",
        "# 主程式碼\n",
        "mx = 0\n",
        "top_notes_list = []  # 存储音乐中所有帧的主要音符\n",
        "\n",
        "\n",
        "for frame_number in tqdm.tqdm(range(FRAME_COUNT)):\n",
        "  \n",
        "    #print(\"Current frame_number:\", frame_number+1)  # 打印当前帧数\n",
        "    # 提取音频样本\n",
        "    sample = extract_sample(audio, frame_number)  # frame_number 是音频数据的帧数或时间点\n",
        "    # 使用汉宁窗口函数进行加权(减少错误)\n",
        "    #sample *= window\n",
        "    # 使用快速傅里叶变换（FFT）计算加权后的音频样本的频谱\n",
        "    fft = np.fft.rfft(sample*window)\n",
        "    # 计算频谱的绝对值（取实部），得到频谱的振幅\n",
        "    fft_abs = np.abs(fft).real\n",
        "    # 更新最大振幅到 mx\n",
        "    mx = max(np.max(fft_abs), mx)\n",
        "    \n",
        "    # 查找该帧的主要音符\n",
        "    #top_notes = find_top_notes(fft_abs, TOP_NOTES)\n",
        "    #top_notes_list.append(fft_abs)\n",
        "\n",
        "    peaks, _ = find_peaks(fft_abs, height=0)  # 这里的 `find_peaks()` 函数需要根据你的具体情况选择\n",
        "\n",
        "    # 从峰值中提取主要音符的频率\n",
        "    main_frequencies = peaks * FRAME_COUNT / len(sample)  # 将峰值对应的索引转换为频率\n",
        "\n",
        "    # 将频率转换为音符数字\n",
        "    main_notes = [freq_to_number(frequency) for frequency in main_frequencies]\n",
        "\n",
        "    top_notes_list.append(main_notes)\n",
        "\n",
        "\n",
        "    \n",
        "# 输出每个主要音符的信息\n",
        "for frame_number, notes in enumerate(top_notes_list, start=1):\n",
        "    for i, note in enumerate(notes, start=1):\n",
        "        print(f\"第 {frame_number} 帧的第 {i} 个主要音符: {note}\")\n",
        "#print(\"總共預期的偵數:\", FRAME_COUNT)  # 打印预期的帧数\n",
        "\n",
        "\n",
        "# 第二遍遍歷，生成動畫\n",
        "for frame_number in tqdm.tqdm(range(FRAME_COUNT)):\n",
        "    # 提取音頻樣本\n",
        "    sample = extract_sample(audio, frame_number)\n",
        "    # 使用漢寧窗口函數進行加權\n",
        "    fft = np.fft.rfft(sample * window)\n",
        "    # 使用快速傅立葉變換（FFT）計算加權後的音頻樣本的頻譜\n",
        "    fft = np.abs(fft) / mx \n",
        "    # 查找頂部音符\n",
        "    s = find_top_notes(fft,TOP_NOTES)   #find_top_notes從 FFT 頻譜中查找頂部音符，即具有最高幅值的音符\n",
        "    # 繪製 FFT 圖譜並標註頂部音符\n",
        "    fig = plot_fft(fft.real, xf, fs, s, RESOLUTION) #plot_fft繪製 FFT 圖譜並在圖上標註頂部音符\n",
        "    # 將圖像保存為圖片文件\n",
        "    !pip install -U kaleido\n",
        "    import kaleido\n",
        "    fig.write_image(f\"/content/frame{frame_number}.png\",scale=2)    #以便之後串成動畫  scale=2將圖片放大2倍存檔，增加解析度\n",
        "\n",
        "\n",
        "#虽然理论上你可以将这两个循环合并为一个，\n",
        "#但在实际中，这样做可能会导致每一帧都必须进行FFT计算两次，这会增加计算量并降低性能。\n",
        "#因此，将这两个循环分开是一种更合理的做法，以便首先找出最大幅值，然后再生成动画。\n",
        "\n",
        "#這段程式碼是用來製作一個音頻頻譜的動畫。\n",
        "#首先，它會遍歷音頻文件的每個小部分（稱為幀），\n",
        "#並計算每個幀的 FFT（快速傅立葉變換），這樣可以將幅值頻譜表示為頻率的函數。\n",
        "#然後，它找到了所有幀中的最大幅值，以便將所有幀的頻譜進行縮放，使其適合於動畫中。\n",
        "#接著，它再次遍歷每個幀，將 FFT 的結果轉換為頻譜圖，並在圖上標註出一些頂部的音符，\n",
        "#最後將每個幀的圖像保存為一個圖像文件，以便後續的動畫製作。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7OinuERiRak",
        "outputId": "fc7be915-90f2-4962-960f-6b736b3d3a38"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/307 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "!ffmpeg -y -r {FPS} -f image2 -s 1920x1080 -i frame%d.png -i {AUDIO_FILE} -c:v libx264 -pix_fmt yuv420p movie.mp4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vo01yEzHeSu"
      },
      "source": [
        "Use [ffmpeg](https://ffmpeg.org/) to combine the input audio WAV and the individual frame images into a MP4 video."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBbcVFuhHZgP"
      },
      "source": [
        "Download the generated movie."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "6ohuRzpfLkYg",
        "outputId": "670480d5-2c9a-43a4-dd13-c4df7ff485d6"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_f063e5f8-2c1c-493f-9df0-27b8296e3100\", \"movie.mp4\", 2339023)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('movie.mp4')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
